# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h19o4XH1_1eUihs-xdXZbAadwPPtSsBy
"""

df = pd.read_csv('/content/dataset-1.csv')

"""**Reverse List by N Elements**"""

def reverse_by_n_elements(lst: List[int], n: int) -> List[int]:
    """
    Reverses the input list by groups of n elements.
    """
    result = []
    length = len(lst)

    for i in range(0, length, n):

        temp = []

        for j in range(i, min(i + n, length)):
            temp.append(lst[j])


        for j in range(len(temp) - 1, -1, -1):
            result.append(temp[j])

    return result


print(reverse_by_n_elements([1, 2, 3, 4, 5, 6, 7, 8], 3))
print(reverse_by_n_elements([1, 2], 3))

"""**Lists & Dictionaries**"""

def group_by_length(lst: List[str]) -> dict[int, List[str]]:

    length_dict = {}

    for string in lst:
        length = len(string)
        if length not in length_dict:
            length_dict[length] = []
        length_dict[length].append(string)


    return dict(sorted(length_dict.items()))


print(group_by_length(["apple", "bat", "car", "elephant", "dog", "bear"]))

"""**Flatten a Nested Dictionary**"""

def flatten_dict(nested_dict: dict[str, any], sep: str = '.') -> dict[str, any]:

    items = {}

    def flatten(current_dict, parent_key=''):
        for key, value in current_dict.items():
            new_key = f"{parent_key}{sep}{key}" if parent_key else key

            if isinstance(value, dict):

                flatten(value, new_key)
            elif isinstance(value, list):

                for i, item in enumerate(value):
                    if isinstance(item, dict):

                        flatten(item, f"{new_key}[{i}]")
                    else:

                        items[f"{new_key}[{i}]"] = item
            else:

                items[new_key] = value

    flatten(nested_dict)
    return items

# Example usage:
nested_dict = {
    "road": {
        "name": "Highway 1",
        "length": 350,
        "sections": [
            {
                "id": 1,
                "condition": {
                    "pavement": "good",
                    "traffic": "moderate"
                }
            }
        ]
    }
}

flattened = flatten_dict(nested_dict)
print(flattened)

"""**Generate Unique Permutations**

> Add blockquote


"""

def unique_permutations(nums: List[int]) -> List[List[int]]:

    def backtrack(start: int):

        if start == len(nums):
            result.append(nums[:])
            return

        seen = set()
        for i in range(start, len(nums)):
            if nums[i] not in seen:
                seen.add(nums[i])
                nums[start], nums[i] = nums[i], nums[start]
                backtrack(start + 1)
                nums[start], nums[i] = nums[i], nums[start]

    result = []
    nums.sort()
    backtrack(0)
    return result


print(unique_permutations([1, 1, 2]))

"""**Find All Dates in a Text**"""

import re
from typing import List

def find_all_dates(text: str) -> List[str]:

    patterns = [
        r'\b([0-2][0-9]|3[0-1])-(0[1-9]|1[0-2])-(\d{4})\b',
        r'\b(0[1-9]|1[0-2])/(0[1-9]|[1-2][0-9]|3[0-1])-(\d{4})\b',
        r'\b(\d{4})\.(0[1-9]|1[0-2])\.(0[1-9]|[1-2][0-9]|3[0-1])\b'
    ]

    valid_dates = []

    for pattern in patterns:
        matches = re.findall(pattern, text)

        for match in matches:
            if pattern == patterns[0]:
                valid_dates.append(f"{match[0]}-{match[1]}-{match[2]}")
            elif pattern == patterns[1]:
                valid_dates.append(f"{match[0]}/{match[1]}-{match[2]}")
            elif pattern == patterns[2]:
                valid_dates.append(f"{match[0]}.{match[1]}.{match[2]}")

    return valid_dates

text = "I was born on 23-08-1994, my friend on 08/23/1994, and another one on 1994.08.23."
print(find_all_dates(text))

"""** Decode Polyline, Convert to DataFrame with Distances**"""

import pandas as pd
import numpy as np
from geopy.distance import geodesic

def decode_polyline(polyline_str: str) -> list:

    poly = []
    index = 0
    lat = 0
    lng = 0

    while index < len(polyline_str):
        b = 0
        shift = 0
        result = 0

        while True:
            b = ord(polyline_str[index]) - 63
            result |= (b & 0x1f) << shift
            shift += 5
            index += 1
            if b < 0x20:
                break

        if result & 1:
            result = ~(result >> 1)
        else:
            result >>= 1
        lat += result

        shift = 0
        result = 0

        while True:
            b = ord(polyline_str[index]) - 63
            result |= (b & 0x1f) << shift
            shift += 5
            index += 1
            if b < 0x20:
                break

        if result & 1:
            result = ~(result >> 1)
        else:
            result >>= 1
        lng += result

        poly.append((lat / 1e5, lng / 1e5))

    return poly

def polyline_to_dataframe(polyline_str: str) -> pd.DataFrame:

    # Decode the polyline
    points = decode_polyline(polyline_str)

    # Create a DataFrame
    df = pd.DataFrame(points, columns=['latitude', 'longitude'])

    # Calculate distances between consecutive points
    distances = []
    for i in range(len(points) - 1):
        distance = geodesic(points[i], points[i + 1]).meters
        distances.append(distance)

    distances.append(0)

    df['distance_m'] = distances
    return df

"""**Matrix Rotation and Transformation**"""

def rotate_and_multiply_matrix(matrix: List[List[int]]) -> List[List[int]]:

    n = len(matrix)


    rotated_matrix = [[0] * n for _ in range(n)]
    for i in range(n):
        for j in range(n):
            rotated_matrix[j][n - 1 - i] = matrix[i][j]


    final_matrix = [[0] * n for _ in range(n)]

    for i in range(n):
        for j in range(n):
            # Calculate the sum of the row and column
            row_sum = sum(rotated_matrix[i])
            col_sum = sum(rotated_matrix[k][j] for k in range(n))
            # Exclude the current element
            final_matrix[i][j] = row_sum + col_sum - rotated_matrix[i][j]

    return final_matrix

matrix = [[1, 2, 3],[4, 5, 6],[7, 8, 9]]
result = rotate_and_multiply_matrix(matrix)
print(result)

"""**Time Check**"""

def time_check(df: pd.DataFrame) -> pd.Series:

    # Combine startDay and startTime into a single datetime column
    df['start_datetime'] = pd.to_datetime(df['startDay'] + ' ' + df['startTime'])
    df['end_datetime'] = pd.to_datetime(df['endDay'] + ' ' + df['endTime'])

    # Group by (id, id_2)
    grouped = df.groupby(['id', 'id_2'])

    # Prepare a list to hold results
    results = []

    for (id_val, id_2_val), group in grouped:
        # Check the time span
        min_time = group['start_datetime'].min()
        max_time = group['end_datetime'].max()

        # Check if the time covers a full 24-hour period
        covers_24_hours = (max_time - min_time).total_seconds() >= 86400  # 86400 seconds in 24 hours

        # Check the days of the week
        days_covered = group['start_datetime'].dt.day_name().unique()
        covers_all_days = len(days_covered) == 7

        # Append the result for this (id, id_2) pair
        results.append(((id_val, id_2_val), not (covers_24_hours and covers_all_days)))

    # Convert results to a Series with multi-index
    result_series = pd.Series(dict(results))

    return result_series